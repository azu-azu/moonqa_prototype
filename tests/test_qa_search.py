import os
import json
import pytest
from datetime import datetime
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from tests.log_utils import validate_log_entry

# âœ… ãƒ­ã‚°å‡ºåŠ›ãƒ•ãƒ©ã‚°ã‚’ pytest ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‹ã‚‰å–å¾—
# --log-output ã‚’ä»˜ã‘ãŸã¨ãã ã‘ logs/qa_log.jsonl ã«è¿½è¨˜ã•ã‚Œã‚‹
def pytest_addoption(parser):
    parser.addoption("--log-output", action="store_true", help="Enable log output")

# âœ… ãƒ†ã‚¹ãƒˆé–¢æ•°å†…ã§ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã« fixture ã‚’å®šç¾©
@pytest.fixture
def log_output_enabled(request):
    return request.config.getoption("--log-output")

# âœ… ãƒ­ã‚°å‡ºåŠ›é–¢æ•°ï¼ˆquery_id å«ã‚€ï¼‰
def append_log_entry(query_id, query, target_pdf, results):
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "query_id": query_id,
        "question": query,
        "target_pdf": target_pdf,
        "result_count": len(results),
        "results": [
            {
                "score": float(score), # float32 â†’ float å¤‰æ›ã§JSONå¯¾å¿œ
                "content": doc.page_content,
                "metadata": doc.metadata
            }
            for doc, score in results
        ]
    }

    with open("logs/qa_log.jsonl", "a", encoding="utf-8") as f:
        f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")

# âœ… è³ªå•ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–
@pytest.mark.parametrize("query_id,query,target_pdf", [
    (q["id"], q["question"], q.get("target_pdf")) for q in json.load(open("data/questions.json", encoding="utf-8"))
])
def test_similarity_search_with_threshold(query_id, query, target_pdf, log_output_enabled):
    # db = â€œãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢â€ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    # ã“ã“ã§å¾—ã‚‰ã‚Œã‚‹ db ã¯ã€ç›´æ¥ .similarity_search_with_score() ã‚„ .similarity_search() ã‚’å®Ÿè¡Œã§ãã‚‹æ¤œç´¢ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    db = FAISS.load_local(
        folder_path="index/faiss_index",
        embeddings=OpenAIEmbeddings(),
        index_name="index",
        allow_dangerous_deserialization=True
    )

    # âœ… filterã‚’æ­£ã—ãæ¸¡ã™ï¼ˆretrieverã¯ä½¿ã‚ãªã„ï¼‰
    search_kwargs = {"k": 3}
    if target_pdf:
        search_kwargs["filter"] = {"pdf_name": target_pdf}

    results = db.similarity_search_with_score(query, **search_kwargs)

    # âœ… ã‚¹ã‚³ã‚¢ã—ãã„å€¤ç¢ºèªãƒ­ã‚°
    threshold = 0.2
    for doc, score in results:
        print(f"[{query_id}] Score: {score:.4f} â†’ {'âœ”ï¸' if score >= threshold else 'Ã—'}")
        print(f"source: {doc.metadata.get('source')}")
        print(f"content: {doc.page_content[:80]}")  # é•·ã™ãã‚‹ã¨ãã¯80æ–‡å­—ã§åˆ‡ã£ã¦ç¢ºèª
        print("-" * 50)

    # âœ… ã‚¹ã‚³ã‚¢ã—ãã„å€¤ãƒ•ã‚£ãƒ«ã‚¿
    filtered = [doc for doc, score in results if score >= threshold]

    assert len(filtered) > 0, f"No relevant documents for query_id: {query_id} (threshold={threshold})"

    # âœ… ãƒ­ã‚°å‡ºåŠ›
    if log_output_enabled:
        append_log_entry(query_id, query, target_pdf, results)


def test_log_entry_structure():
    log_path = "logs/qa_log.jsonl"
    if not os.path.exists(log_path) or os.path.getsize(log_path) == 0:
        pytest.skip("ğŸŒ’ãƒ­ã‚°ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ãŸã‚“ã‚ˆ")
    validate_log_entry(log_path)