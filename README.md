# MoonQA Prototype ğŸŒ™

This is a prototype QA system built with LangChain, designed to answer questions from a PDF document about the moon.
It uses vector search (FAISS) and OpenAI's language model to provide accurate, context-based answers.

---

## ğŸŒŒ Project Overview

- **Purpose**: Test the ability to convert a PDF into vector data and query it using a natural language interface
- **PDF Input**: `data/about_moon.pdf`
- **Architecture**:
  - Text splitting with LangChain's `RecursiveCharacterTextSplitter`
  - Embedding via `OpenAIEmbeddings`
  - Vector store: FAISS
  - LLM: `ChatOpenAI (gpt-3.5-turbo)`
  - CLI-based query execution

---

## ğŸ—‚ Directory Structure

```
moonqa_prototype/
â”œâ”€â”€ app/                 # Core logic (ingest, QA)
â”œâ”€â”€ data/                # PDF source files
â”œâ”€â”€ index/faiss_index/   # Vector index files (.faiss / .pkl)
â”œâ”€â”€ logs/                # Markdown logs of questions and answers
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml
â””â”€â”€ main.py              # Entry point
```

---

## ğŸš€ How to Use

1. **Install dependencies** with Poetry:

   ```bash
   poetry install
   ```

2. **Set your OpenAI API key** in `.env`:

   ```
   OPENAI_API_KEY=your-key-here
   ```

3. **Run ingestion** to process the PDF:

   ```bash
   poetry run python app/ingest.py
   ```

4. **Ask a question via CLI**:

   ```bash
   poetry run python app/qa.py --question "æœˆã«ã¯æ°´ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ"
   ```

---

## ğŸ“’ Output

Each question/answer pair is appended to `logs/qa_log.md` in the following Markdown format:

```markdown
## ğŸ’¬ Question
æœˆã«ã¯æ°´ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ

## ğŸ“– Answer
æœˆã®è¡¨é¢ã«ã¯ã€Œæµ·ã€ã¨å‘¼ã°ã‚Œã‚‹å¹³ã‚‰ãªåœ°å½¢ãŒã‚ã‚Šã¾ã™ãŒã€å®Ÿéš›ã«ã¯æ°´ã¯å­˜åœ¨ã—ã¾ã›ã‚“ã€‚

---
```

---

## ğŸ“Œ Notes

- This is a **prototype**, not production-ready
- LLM calls may incur OpenAI API costs
- `.env` is ignored and should not be committed

---

## ğŸ“˜ License

This repository is currently private and intended for internal testing only.
